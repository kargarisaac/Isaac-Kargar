---
title: "RL Series"
description: "Series of posts on different RL algorithms"
layout: post
toc: true
comments: true
hide: false
search_exclude: true
categories: [fastpages]
---

![]({{ site.baseurl }}/images/posts_images/rl-series/rl-diagram.png "Reinforcement Learning Diagram")

# RL Series

I decided to read and learn more about different RL algorithms. Here is a list of the algorithms that I hope I can learn about: (I try to select the correct name for different techniques as much as I can)

- DQN
- REINFORCE
- A2C and A3C
- TRPO
- PPO
- DDPG
- SAC
- Ape-X
- R2D2
- IMPALA
- Never Give-Up
- Agent57
- MADDPG
- COMA
  
Maybe I try a technique on several environments or several techniques on an environment. I also hope that I can implement some model-based RL and multi-agent RL techniques too. I will work on self-driving cars and RL in my PhD and will try to test some of these techniques in some environments such as CARLA or CarRacing gym env.
There are a lot of good resources to learn about RL that I will use and you can find some of them here:

- [David Silver RL course](https://www.youtube.com/watch?list=PLzuuYNsE1EZAXYR4FJ75jcJseBmo4KQ9-&v=2pWv7GOvuf0)
- [CS 285 at UC Berkeley- Deep Reinforcement Learning](http://rail.eecs.berkeley.edu/deeprlcourse/)
- [CS234: Reinforcement Learning Winter 2020](http://web.stanford.edu/class/cs234/index.html)
- [CS885: Reinforcement Learning tought by Prof. Poupart - University of Waterloo](https://www.youtube.com/watch?list=PLdAoL1zKcqTXFJniO3Tqqn6xMBBL07EDc&v=xoxz-OmcL1Q)
- [Arthur Juliani's blog posts](https://medium.com/@awjuliani)
- [Jonathan Hui's blog posts](https://medium.com/@jonathan_hui/rl-deep-reinforcement-learning-series-833319a95530)
- [Thomas Simonini's blog posts](https://simoninithomas.github.io/Deep_reinforcement_learning_Course/)
  
And many more resources that you can find through the internet.
I reviewed these resources through the #100DaysOfMLCode challenge, the RL course at Aalto University and the studies that I’m doing for my PhD. I think that’s it for this post. We will continue with DQN in the next post.