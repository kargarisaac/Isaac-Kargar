{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Data Engineering - Week 1\"\n",
    "> \"This is week 1 from the Data Engineering Zoomcamp.\"\n",
    "\n",
    "- toc: True\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [data engineering, jupyter]\n",
    "- image: images/some_folder/your_image.png\n",
    "- hide: false\n",
    "- search_exclude: true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the video of this wee:\n",
    "\n",
    "> youtube: https://youtu.be/bkJZDmreIpA\n",
    "\n",
    "github repo: https://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/dataset.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Cloud Platform\n",
    "\n",
    "Introduction of Google cloud services:\n",
    "\n",
    "> youtube: https://youtu.be/18jIzE41fJ4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docker\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> youtube: https://youtu.be/EYNwNlOrpr0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline.py\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "print(sys.argv)\n",
    "day = sys.argv[1]\n",
    "# some fancy stuff with pandas\n",
    "\n",
    "print(f'job finished successfully for day = {day}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dockerfile\n",
    "\n",
    "FROM python:3.9.1 #the base image to start from\n",
    "\n",
    "RUN pip install pandas #run a command to install python packages\n",
    "\n",
    "WORKDIR /app #change the working directory - it's like cd command in linux \n",
    "COPY pipeline.py pipeline.py # copy the file from current folder in the host machine to the working directory\n",
    "\n",
    "ENTRYPOINT [ \"python\", \"pipeline.py\" ] # run the python pipeline.py command when we use docker run command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use the following command to build the image from Dockerfile in the current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker build -t test:pandas ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PostgreSQL\n",
    "\n",
    "> youtube: https://youtu.be/2JM-ziJt0WI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run *postgres:13* image database with some environment commands (specified by -e), mapping local folder from host machine to a path in docker container (using -v flag), and on port 5432 which will be used for connecting to the database from outside (our python code for example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker run -it \\\n",
    "> -e POSTGRES_USER=\"root\" \\\n",
    "> -e POSTGRES_PASSWORD=\"root\" \\\n",
    "> -e POSTGRES_DB=\"ny_taxi\" \\\n",
    "> -v $(pwd)/ny_taxi_postgres_data:/var/lib/postgresql/data \\\n",
    "> -p 5432:5432 \\\n",
    "> postgres:13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pgcli is a python package for connecting to the postgres database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pgcli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgcli -h localhost -p 5432 -u root -d ny_taxi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download data from [here]( https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page) and under `2021 > January > Yellow Taxi Trip Records`. The file name is *yellow_tripdata_2021-01.csv*.\n",
    "\n",
    "Using the following codes you can load and visualize and import data to postgres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# create engine and set the root as postgresql://user:password@host:port/database\n",
    "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi')\n",
    "\n",
    "df_iter = pd.read_csv('yellow_tripdata_2021-01.csv', iterator=True, chunksize=100000)\n",
    "\n",
    "while True: \n",
    "    df = next(df_iter)\n",
    "    df.tpep_pickup_datetime = pd.to_datetime(df.tpep_pickup_datetime)\n",
    "    df.tpep_dropoff_datetime = pd.to_datetime(df.tpep_dropoff_datetime)\n",
    "    df.to_sql(name='yellow_taxi_data', con=engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
