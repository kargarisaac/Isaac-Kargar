{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eeba3b2",
   "metadata": {},
   "source": [
    "# \"MLOps project- part 2: Machine Learning Workflow Orchestration using Prefect and ZenML\"\n",
    "> \"Machine learning workflow orchestration.\"\n",
    "\n",
    "- toc: True\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [mlops]\n",
    "- image: images/some_folder/your_image.png\n",
    "- hide: false\n",
    "- search_exclude: true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809055aa",
   "metadata": {},
   "source": [
    "In the previous blog post, we saw how to train a model and track experiments using MLflow.\n",
    "In the second blog post in this series, we will get the code from previous step and convert it into a machine learning pipeline. I will show how to do it using two popular tools: Prefect and ZenML. There are many amazing tools out there which we cannot cover here such as Flyte, Kale, Aro, etc..\n",
    "\n",
    "But why do we need a pipeline for our machine learning services? ZenML documentation explains it clearly [[source](https://github.com/zenml-io/zenbytes)]:\n",
    "\n",
    "> As an ML practitioner, you are probably familiar with building ML models using Scikit-learn, PyTorch, TensorFlow, or similar. An **[ML Pipeline](https://docs.zenml.io/developer-guide/steps-and-pipelines)** is simply an extension, including other steps you would typically do before or after building a model, like data acquisition, preprocessing, model deployment, or monitoring. The ML pipeline essentially defines a step-by-step procedure of your work as an ML practitioner. Defining ML pipelines explicitly in code is great because: <br>\n",
    "> - We can easily rerun all of our work, not just the model, eliminating bugs and making our models easier to reproduce.\n",
    "> - Data and models can be versioned and tracked, so we can see at a glance which dataset a model was trained on and how it compares to other models.\n",
    "> - If the entire pipeline is coded up, we can automate many operational tasks, like retraining and redeploying models when the underlying problem or data changes or rolling out new and improved models with CI/CD workflows.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d219d6",
   "metadata": {},
   "source": [
    "We may have extensive preprocessing that we do not want to repeat every time we train a model, such as in the last blog post where we generated the 'corpus' list.\n",
    "We may also need to compare the performance of different models, or wish to deploy the model and monitor data and model performance. Here, ML pipelines come into play, allowing us to specify our workflows as a series of modular processes that can subsequently be combined.\n",
    "\n",
    "Additionally, we may have a machine learning pipeline that we would like to execute every week. We can put it on a timetable, and if the machine learning model fails or the incoming data fails, we can analyze and resolve the issues.\n",
    "\n",
    "Let's consider a standard machine learning pipeline:\n",
    "\n",
    "![](images/workflow-orchestration/1.png)\n",
    "*[source](https://www.youtube.com/watch?v=eKzCjNXoCTc&list=PL3MmuxUbc_hIUISrluw_A7wDSmfOhErJK&index=22)*\n",
    "\n",
    "First, we have a postgresql database and perhaps a task that produces some data into a parquet file. Next, we use pandas to ingest the parquet file and combine it with API data that we're pulling.\n",
    "After training the model, we register the artifact and experiment with MLflow, and if certain requirements are met, we may deploy the model using Flask, for instance.\n",
    "Clearly, all of these phases are interdependent, and if one fails, the entire pipeline will be affected.\n",
    "Failure can even occur in unexpected ways. For instance, the incoming data is faulty, the API randomly fails to connect, and the same is true for MLflow. Perhaps you are utilizing a database to store MLflow artifacts, such as experiments, and there is a problem. All of these are regular occurrences, and the purpose of workflow orchestration is to both reduce the impact of these failures and aid in their resolution.\n",
    "\n",
    "![](images/workflow-orchestration/2.png)\n",
    "*[source](https://www.youtube.com/watch?v=eKzCjNXoCTc&list=PL3MmuxUbc_hIUISrluw_A7wDSmfOhErJK&index=22)*\n",
    "\n",
    "\n",
    "\n",
    "<!-- We can identify three distinct steps in our example: data loading, model training, and model evaluation. Let us now define each of them as a ZenML **[Pipeline Step](https://docs.zenml.io/developer-guide/steps-and-pipelines#step)** simply by moving each step to its own function and decorating them with ZenML's `@step` [Python decorator](https://realpython.com/primer-on-python-decorators/). -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4535c97c",
   "metadata": {},
   "source": [
    "All of these will aid the organization and its developers in completing their tasks and locating issues more quickly, allowing them to devote their attention to something more vital.\n",
    "\n",
    "Great! let's see how we can do it in practice. First, let's see how Prefect can help us."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9332182",
   "metadata": {},
   "source": [
    "# Prefect\n",
    "\n",
    "We will use p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9ede7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb4463b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9212e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05060556",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5858722",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58776d03",
   "metadata": {},
   "source": [
    "# ZenML\n",
    "\n",
    "[ZenML](https://github.com/zenml-io/zenml/) is an excellent tool for this task, as it is straightforward and intuitive to use and has [integrations](https://docs.zenml.io/mlops-stacks/integrations) with most of the advanced MLOps tools we will want to use later. Make sure you have ZenML installed (via `pip install zenml`). Let's run some commands to make sure you start with a fresh ML stack. You can ignore the details for now, as we will learn about it in more detail in a later chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9af589",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a102fb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
