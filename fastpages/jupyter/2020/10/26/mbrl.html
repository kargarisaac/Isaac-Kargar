<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Model Based Reinforcement Learning (MBRL) | Isaac Kargar</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Model Based Reinforcement Learning (MBRL)" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="This is a summary of MBRL from ICML-2020 tutorial." />
<meta property="og:description" content="This is a summary of MBRL from ICML-2020 tutorial." />
<link rel="canonical" href="https://kargarisaac.github.io/blog/fastpages/jupyter/2020/10/26/mbrl.html" />
<meta property="og:url" content="https://kargarisaac.github.io/blog/fastpages/jupyter/2020/10/26/mbrl.html" />
<meta property="og:site_name" content="Isaac Kargar" />
<meta property="og:image" content="https://kargarisaac.github.io/blog/images/some_folder/your_image.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-10-26T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"This is a summary of MBRL from ICML-2020 tutorial.","@type":"BlogPosting","headline":"Model Based Reinforcement Learning (MBRL)","url":"https://kargarisaac.github.io/blog/fastpages/jupyter/2020/10/26/mbrl.html","datePublished":"2020-10-26T00:00:00-05:00","dateModified":"2020-10-26T00:00:00-05:00","image":"https://kargarisaac.github.io/blog/images/some_folder/your_image.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://kargarisaac.github.io/blog/fastpages/jupyter/2020/10/26/mbrl.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://kargarisaac.github.io/blog/feed.xml" title="Isaac Kargar" /><link rel="shortcut icon" type="image/x-icon" href="/blog/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Model Based Reinforcement Learning (MBRL) | Isaac Kargar</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Model Based Reinforcement Learning (MBRL)" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="This is a summary of MBRL from ICML-2020 tutorial." />
<meta property="og:description" content="This is a summary of MBRL from ICML-2020 tutorial." />
<link rel="canonical" href="https://kargarisaac.github.io/blog/fastpages/jupyter/2020/10/26/mbrl.html" />
<meta property="og:url" content="https://kargarisaac.github.io/blog/fastpages/jupyter/2020/10/26/mbrl.html" />
<meta property="og:site_name" content="Isaac Kargar" />
<meta property="og:image" content="https://kargarisaac.github.io/blog/images/some_folder/your_image.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-10-26T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"This is a summary of MBRL from ICML-2020 tutorial.","@type":"BlogPosting","headline":"Model Based Reinforcement Learning (MBRL)","url":"https://kargarisaac.github.io/blog/fastpages/jupyter/2020/10/26/mbrl.html","datePublished":"2020-10-26T00:00:00-05:00","dateModified":"2020-10-26T00:00:00-05:00","image":"https://kargarisaac.github.io/blog/images/some_folder/your_image.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://kargarisaac.github.io/blog/fastpages/jupyter/2020/10/26/mbrl.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://kargarisaac.github.io/blog/feed.xml" title="Isaac Kargar" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head><body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/">Isaac Kargar</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/about/">About Me</a><a class="page-link" href="/blog/search/">Search</a><a class="page-link" href="/blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Model Based Reinforcement Learning (MBRL)</h1><p class="page-description">This is a summary of MBRL from ICML-2020 tutorial.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-10-26T00:00:00-05:00" itemprop="datePublished">
        Oct 26, 2020
      </time>
       â€¢ <span class="read-time" title="Estimated read time">
    
    
      5 min read
    
</span></p>

    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/kargarisaac/blog/tree/master/_notebooks/2020-10-26-mbrl.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/blog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/kargarisaac/blog/master?filepath=_notebooks%2F2020-10-26-mbrl.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/kargarisaac/blog/blob/master/_notebooks/2020-10-26-mbrl.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-10-26-mbrl.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This post is a summary of the model-based RL tutorial at ICML-2020. You can find the videos <a href="https://sites.google.com/view/mbrl-tutorial">here</a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Introduction-and-Motivation">Introduction and Motivation<a class="anchor-link" href="#Introduction-and-Motivation"> </a></h2><p>Having access to a model of the world and using it for decision making is a powerful idea. 
There are a lot of applications of MBRL in different areas like robotics (manipulation- what will happen by doing an action), 
self-driving cars (having a model of other agents decisions and future motions and act accordingly),
games (AlphaGo- search over different possibilities), Science ( chemical usecases),
and peration research and energy applications (how to allocate renewable energy in different points in time to meet the demand).</p>
<h2 id="Problem-Statement">Problem Statement<a class="anchor-link" href="#Problem-Statement"> </a></h2><p>In sequential decision making, the agent will interact with the world by doing action $a$ and getting the next state $s$ and reward $r$.</p>
<p><figure>
  
    <img class="docimage" src="/blog/images/copied_from_nb/images/rl.png" alt="" />
    
    
</figure>
</p>
<p>We can write this problem as a Markov Decision Process (MDP) as follows:</p>
<ul>
<li>States $S \epsilon R^{d_S}$</li>
<li>Actions $A \epsilon R^{d_A}$</li>
<li>Reward function $R: S \times A \rightarrow R$</li>
<li>Transition function $T: S \times A \rightarrow S$</li>
<li>Discount $\gamma \epsilon (0,1)$</li>
<li>Policy $\pi: S \rightarrow A$</li>
</ul>
<p>The goal is to find a policy which maximizes the sum of discounted future rewards:
$$
argmax_{\pi} \sum_{t=0}^\inf \gamma^t R(s_t, a_t)
$$
subject to
$$
a_t = \pi(s_t) , s_{t+1}=T(s_t, a_t)
$$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>How to solve this optimization problem?!</p>
<ul>
<li>Collect data $D= \{ s_t, a_t, r_{t+1}, s_{t+1} \}_{t=0}^T$.</li>
<li>Model-free: learn policy directly from data</li>
</ul>
<p>$ D \rightarrow \pi$ e.g. Q-learning, policy gradient</p>
<ul>
<li>Model-based: learn model, then use it to <strong>learn</strong> or <strong>improve</strong> a policy </li>
</ul>
<p>$ D \rightarrow f \rightarrow \pi$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="What-is-a-model?">What is a model?<a class="anchor-link" href="#What-is-a-model?"> </a></h2><p>a model is a representation that explicitly encodes knowledge about the structure of the environment and task.</p>
<p>This model can take a lot of different forms:</p>
<ul>
<li>A transition/dynamic model: $s_{t+1} = f_s(s_t, a_t)$</li>
<li>A model of rewards: $r_{t+1} = f_r(s_t, a_t)$</li>
<li>An inverse transition/dynamics model (which tells you what is the action to take and go from one state to the next state): $a_t = f_s^{-1}(s_t, s_{t+1})$</li>
<li>A model of distance of two states: $d_{ij} = f_d(s_i, s_j)$</li>
<li>A model of future returns: $G_t = Q(s_t, a_t)$ or $G_t = V(s_t)$</li>
</ul>
<p>Typically when someone says MBRL, he/she means the firs two items.</p>
<p><figure>
  
    <img class="docimage" src="/blog/images/copied_from_nb/images/model.png" alt="" />
    
    
</figure>
</p>
<p>Sometimes we know the ground truth dynamics and rewards. Might as well use them! Like game environments or simulators like Mujoco, Carla, and so on.</p>
<p>But we don't have access to the model in all cases, so we need to learn the model. In cases like in robots, complex physical dynamics, and interaction with humans.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="How-to-use-model?">How to use model?<a class="anchor-link" href="#How-to-use-model?"> </a></h2><p>In model-free RL agent we have a policy and learning algorithm like the figure below:</p>
<p><figure>
  
    <img class="docimage" src="/blog/images/copied_from_nb/images/rl2.png" alt="" />
    
    
</figure>
</p>
<p>In model-based RL we can use the model in three different ways:</p>
<ul>
<li>simulating the environment: replacing the environment with model and use it to generate data and use it to update the policy.</li>
<li>Assisting the learning algorithm: modify the learning algorithm to use the model to interpret the data it is getting in a different way. </li>
<li>Strengthening the policy: allow the agent at test time to use the model to try out different actions before it commits to one of them (taking the action in the real world).</li>
</ul>
<p><figure>
  
    <img class="docimage" src="/blog/images/copied_from_nb/images/mbrl.png" alt="" />
    
    
</figure>
</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In general, to compare model-free and model-based:</p>
<p><figure>
  
    <img class="docimage" src="/blog/images/copied_from_nb/images/mbrl_vs_mfrl.png" alt="" />
    
    
</figure>
</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="How-to-learn-a-model?">How to learn a model?<a class="anchor-link" href="#How-to-learn-a-model?"> </a></h2><p>There are two different dimensions that are useful to pay attention to:</p>
<ul>
<li><p>representation of the features for the states that the model is being learned over them</p>
</li>
<li><p>representation of the transition between states</p>
</li>
</ul>
<p><figure>
  
    <img class="docimage" src="/blog/images/copied_from_nb/images/learn_model.png" alt="" />
    
    
</figure>
</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In continue we take a look at different transition models.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="state-transition-models">state-transition models<a class="anchor-link" href="#state-transition-models"> </a></h3><p>In some cases, we know equations of motion and dynamics but we don't know the exact parameters like mass. We can use system identification to estimate unknown parameters like mass. But these sort of cases require having a lot of domain knowledge about how exactly the system works.</p>
<p><figure>
  
    <img class="docimage" src="/blog/images/copied_from_nb/images/learn_model2.png" alt="" />
    
    
</figure>

<figure>
  
    <img class="docimage" src="/blog/images/copied_from_nb/images/learn_model3.png" alt="" />
    
    
</figure>
</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In some cases that we don't know the dynamics of motion, we can simply use an MLP to get a concatenation of $s_t, a_t$ and output the next state $s_{t+1}$.</p>
<p><figure>
  
    <img class="docimage" src="/blog/images/copied_from_nb/images/learn_model4.png" alt="" />
    
    
</figure>
</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In cases that we have some, not perfect, domain knowledge about the environment, we can use graph neural networks (GNNs) to model the agent (robot). For example in Mujoco we can model a robot (agent) with nodes as its body parts and edges as joint and learn the physics engine.</p>
<p><figure>
  
    <img class="docimage" src="/blog/images/copied_from_nb/images/learn_model5.png" alt="" />
    
    
</figure>
</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="observation-transition-models">observation-transition models<a class="anchor-link" href="#observation-transition-models"> </a></h3><p>In this cases, we don't have access to states (low level states like joint angles), but we have access to images. The MDP for this cases would be like this:</p>
<p><figure>
  
    <img class="docimage" src="/blog/images/copied_from_nb/images/learn_model6.png" alt="" />
    
    
</figure>
</p>
<p>So what can we do with this?</p>
<ul>
<li>Directly predict transitions between observations (observation-transition models)</li>
</ul>
<p><figure>
  
    <img class="docimage" src="/blog/images/copied_from_nb/images/learn_model7.png" alt="" />
    
    
</figure>
</p>
<ul>
<li>Reconstruct observation at every timestep: Using sth like LSTMs. Here we need to reconstruct the whole observation in each timestep. The images can be blurry in these cases.</li>
</ul>
<p><figure>
  
    <img class="docimage" src="/blog/images/copied_from_nb/images/learn_model8.png" alt="" />
    
    
</figure>
</p>
<p><figure>
  
    <img class="docimage" src="/blog/images/copied_from_nb/images/learn_model88.png" alt="" />
    
    
</figure>
</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="latent-state-transition-models">latent state-transition models<a class="anchor-link" href="#latent-state-transition-models"> </a></h3><p>Another option when we have just access to observation is to instead of making transition between observations we can infere a latent state and then make transitions in that latent space (latent state-transition models) not in the observation space. It would be much faster than reconstructing the observation on every timestep. We take our initial observation or perhaps the last couple of observations and embed them into the latent state and then unroll it in time and do predictions in $z$ instead of $o$.</p>
<p><figure>
  
    <img class="docimage" src="/blog/images/copied_from_nb/images/learn_model9.png" alt="" />
    
    
</figure>
</p>
<p>Usually we use the observation and reconstruct it during training but at test time we can unroll it very quickly. we can also reconstruct observation at each timestep we want (not necessarily in all timesteps).</p>
<p><figure>
  
    <img class="docimage" src="/blog/images/copied_from_nb/images/learn_model10.png" alt="" />
    
    
</figure>
</p>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="kargarisaac/blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/blog/fastpages/jupyter/2020/10/26/mbrl.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>My posts about Machine Learning</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/kargarisaac" title="kargarisaac"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://www.linkedin.com/in/eshagh-kargar" title="eshagh-kargar"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#linkedin"></use></svg></a></li><li><a rel="me" href="https://twitter.com/kargarisaac" title="kargarisaac"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
